{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import cPickle\n",
    "import patsy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimators support arguments to control the fitting behaviour -- these arguments are often called hyperparameters. Among the most important ones for GBRT are:\n",
    "\n",
    "* number of regression trees (n_estimators)\n",
    "* depth of each individual tree (max_depth)\n",
    "* loss function (loss)\n",
    "* learning rate (learning_rate)\n",
    "\n",
    "For example if you want to fit a regression model with 100 trees of depth 3 using least-squares:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Hyperparameter tuning\n",
    "\n",
    "太耗时间了 12h+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X = train_data[0:, 1:]\n",
    "# y = train_data[0:, 0]\n",
    "\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.1, 0.05],\n",
    "#     'max_depth': [4, 6],\n",
    "#     'min_samples_leaf': [3, 9, 17],\n",
    "#     #'max_features': [1.0, 0.3, 0.1]\n",
    "# }\n",
    "# est = GradientBoostingClassifier(n_estimators=500)\n",
    "# gs_cv = GridSearchCV(est, param_grid).fit(X, y)\n",
    "# # best hyperparameter setting\n",
    "# gs_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('data/train_set/1212train_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data = train_set.values\n",
    "formula = 'buy ~ f3_1 + f3_2 + f3_3 + f3_4 + \\\n",
    "                 f3_5 + f3_6 + f3_7 + f3_8 + \\\n",
    "                 f1_1_3 + f1_1_7 + f1_2_3 + f1_2_7 + f1_3_3 + f1_3_7 + \\\n",
    "                 f2_1 + np.true_divide(f3_4, f2_1+0.01)'# + np.true_divide(f2_1, f2_2)'\n",
    "# 用patsy的dmatrices生成一个对 友好的dataframe\n",
    "y, x = patsy.dmatrices(formula, data=train_set, return_type='dataframe')\n",
    "\n",
    "x = x.values[0:, 1:]\n",
    "y = y.values[0:, 0]\n",
    "\n",
    "est = GradientBoostingClassifier(n_estimators=400, max_depth=4, min_samples_leaf=2)\n",
    "est.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('models/f16_gbrt 1212[n_estimators=400,max_depth=4, min_samples_leaf=2].pickle', 'w')\n",
    "cPickle.dump(est, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('data/test_set/1212test_set.csv')\n",
    "#test_data = test_set.values\n",
    "test_set['buy'] = 0\n",
    "\n",
    "# formula = 'buy ~ f3_1 + f3_2 + f3_3 + f3_4 + \\\n",
    "#                  f3_5 + f3_6 + f3_7 + f3_8 + \\\n",
    "#                  f2_1 + np.true_divide(f3_4, f2_1+0.01)'# + np.true_divide(f2_1, f2_2)'\n",
    "# 用patsy的dmatrices生成一个对 友好的dataframe\n",
    "y, x = patsy.dmatrices(formula, data=test_set, return_type='dataframe')\n",
    "\n",
    "x = x.values[:, 1:]\n",
    "y = y.values[:, 0]\n",
    "\n",
    "#output = est.predict(test_data[0:, 2:])\n",
    "output_prob = est.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_set = pd.read_csv(\"data/test_set/1212ui_set.csv\")\n",
    "\n",
    "print 'predicting ...'\n",
    "predict_set['buy'] = output_prob[0:,1]\n",
    "print 'predict done'\n",
    "\n",
    "predict_set.to_csv(\"data/output/gbrt/f16_predict_set 1212 400 4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict_set = pd.read_csv('data/output/gbrt/predict_set.csv')\n",
    "\n",
    "# recomm_set = predict_set.sort(columns=['buy'], ascending=False)[:421][['user_id','item_id']]\n",
    "# recomm_set.to_csv(\"data/output/gbrt/tianchi_mobile_recommendation_predict.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print 'ok'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
